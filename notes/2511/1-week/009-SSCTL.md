### 1. 一段话总结
北京航空航天大学、中国科学院与美团团队提出**SSCTL（Soft-partitioned Semi-supervised Collaborative Transfer Learning）**——一种面向多域推荐（MDR）的软划分半监督协同迁移学习框架，旨在解决传统共享-特定参数架构在**数据不平衡场景**下的两大核心问题：（1）**主导域压倒性（Overwhelming）**：主导域数据（如美团外卖首页占81.16%流量）主导共享参数学习，忽视非主导域；（2）**非主导域过拟合（Overfitting）**：非主导域数据稀疏（如部分域仅占0.59%流量）导致特定参数过拟合。SSCTL通过两大模块协同优化：一是**实例软划分协同训练（ISCT）**，将主导域数据视为无标签样本，生成带权重的伪标签（基于截断高斯函数计算权重）以增强非主导域数据，缓解过拟合；二是**软划分域分化网络（SDDN）**，基于域概率分布生成动态参数，放大非主导域样本对共享参数的影响，削弱主导域压倒性。在**Ali-CCP公共数据集**与**美团外卖工业数据集**上，SSCTL的AUC值均显著优于HMoE、STAR等基线（如美团D6域AUC达0.6817，相对提升12.47%）；线上A/B测试中，SSCTL使**GMV提升0.54%-2.90%**，**CTR提升0.22%-1.69%**，验证了其工业实用性。


---

### 2. 思维导图（mindmap）
```mermaid
graph LR
A[论文核心：SSCTL-一种面向多域推荐（MDR）的软划分半监督协同迁移学习框架] --> B[基础信息]

B --> B1[论文标题：A Soft-partitioned Semi-supervised Collaborative Transfer Learning Approach for Multi-Domain Recommendation]
B --> B2[作者：Xiaoyu Liu, Yiqing Wu, Ruidong Han, Fuzhen Zhuang, Xiang Li, Wei Lin]
B --> B3[学科分类：Information Retrieval （cs.IR）、Machine Learning]
B --> B4[核心框架：SSCTL]

A --> C[研究背景与挑战]

C --> C1[多域推荐（MDR）工业痛点]
C1 --> C11[数据极端不平衡：主导域占81.16%流量，非主导域最低仅0.59%]
C1 --> C12[用户/物品高重叠：非主导域与主导域物品重叠74.53%-85.75%，用户重叠90.97%-99.12%]
C --> C2[传统共享-特定架构局限]
C2 --> C21[主导域压倒性：共享参数被主导域数据主导，非主导域知识未利用]
C2 --> C22[非主导域过拟合：特定参数仅依赖稀疏数据训练，泛化性差]
C2 --> C23[硬划分缺陷：依赖域指示器静态划分，忽略域边界模糊性（如用户跨域随机行为）]
C --> C3[研究目标：软划分+半监督迁移，平衡多域性能]

A --> D[SSCTL框架设计]

D --> D1[核心定位：工业级多域推荐框架，适配CTR预测任务]
D --> D2[基础骨干架构（类似CGC）]
D2 --> D21[特征嵌入层：将通用（F_G）、上下文（F_C）、域特征（F_D）转为嵌入，r_e输入专家，r_g输入门控网络]
D2 --> D22[专家层：m个共享专家（f_i（·））+N个特定专家（g^k（·）），输出隐藏表示h_i^k与s^k]
D2 --> D23[门控网络：MLP生成权重w，聚合共享与特定表示z=Σw_i h_i^k ⊕ s^k]
D2 --> D24[预测塔：t(z)输出CTR预测值ŷ]
D --> D3[两大核心模块]
D3 --> D31[实例软划分协同训练（ISCT）]
D31 --> D311[步骤1：划分数据→主导域x^d（无标签）、非主导域x^o（有标签）]
D31 --> D312[步骤2：用x^o训练分类器C（·），生成x^d的伪标签ȳ_i^d与置信度c_i]
D31 --> D313[步骤3：截断高斯函数G（·）计算伪标签权重，EMA估计高斯参数μ/σ]
D31 --> D314[步骤4：总损失=L（真实标签）+λ×L（伪标签权重），λ=0.7]
D3 --> D32[软划分域分化网络（SDDN）]
D32 --> D321[步骤1：分类器C（·）输出样本域概率分布p，加权域嵌入e_w=Σp_k e_d^k]
D32 --> D322[步骤2：分化网络（DN）生成尺度向量γ_ld（硬划分）与γ_lw（软划分）]
D32 --> D323[步骤3：动态参数调整h_l=√（γ_ld⊗γ_lw） ⊗ FC_l（h_（l-1）），δ=2约束尺度]
D --> D4[关键创新：软划分替代硬划分，半监督迁移利用主导域数据]

A --> E[实验验证]

E --> E1[实验设置]
E1 --> E11[数据集：Ali-CCP（公共）、美团外卖（工业，6个域）]
E1 --> E12[基线：MLP、DeepFM、MMoE、HMoE、STAR、AdaSparse等]
E1 --> E13[指标：AUC（离线）、GMV/CTR（线上）、相对提升率（RImp）]
E --> E2[关键结果]
E1 --> E21[离线：美团D6域AUC达0.6817（基线最高0.6777，RImp+12.47%）]
E2 --> E22[线上：5个域GMV提升0.54%-2.90%，CTR提升0.22%-1.69%]


A --> F[结论与价值]

F --> F1[结论：SSCTL通过软划分与半监督迁移，解决数据不平衡下的两大核心问题]
F --> F2[价值：1）工业适配：线上GMV/CTR显著提升；2）泛化性强：适配公共与工业数据集；3）插件化：SDDN可灵活集成于现有架构]
```


---

### 3. 详细总结
#### 一、研究背景：多域推荐的工业挑战
1. **多域推荐的实际场景特征**  
   大型商业平台（如美团外卖）通常包含多个推荐域，但存在显著的数据与行为特性：
   - **数据极端不平衡**：如表1所示，主导域（D1，首页）占81.16%流量，非主导域（D2-D6）流量占比12.57%-0.59%，部分域数据极度稀疏；
   - **用户/物品高重叠**：非主导域与主导域的物品重叠率74.53%-85.75%，用户重叠率90.97%-99.12%，表明跨域存在可迁移的知识。

2. **传统共享-特定参数架构的局限**  
   现有MDR方法（如HMoE、STAR）采用“共享参数捕捉跨域共性+特定参数捕捉域特性”，但在数据不平衡场景下存在两大问题：
   - **主导域压倒性（Overwhelming）**：共享参数训练中，主导域数据量远超其他域，导致模型过度拟合主导域模式，忽视非主导域的独特需求；
   - **非主导域过拟合（Overfitting）**：非主导域数据稀疏，特定参数仅能通过少量样本学习，易出现过拟合，泛化性差；
   - **硬划分缺陷**：依赖静态域指示器划分数据，无法捕捉域边界的模糊性（如用户可能随机在首页与子域购买同一类商品）。


#### 二、SSCTL框架设计
SSCTL以“软划分+半监督迁移”为核心，在传统共享-特定架构基础上，新增**ISCT**与**SDDN**两大模块，架构如图1所示。

##### 1. 基础骨干架构（Backbone）
采用类似CGC的结构，包含五大组件，为后续模块提供基础表示：
| 组件               | 功能描述                                                                 | 关键公式/参数                                                                 |
|--------------------|--------------------------------------------------------------------------|-------------------------------------------------------------------------------|
| 特征嵌入层         | 将输入特征转为嵌入向量，区分专家输入与门控输入                             | $`(r_e = E(F_G) \oplus E(F_C))`$（专家输入）；$`(r_g = E(F_C) \oplus E(F_D))`$（门控输入） |
| 专家层             | 捕捉跨域共性与域特性，含m个共享专家与N个特定专家                          | 共享专家：$`(h_i^k = f_i(r_e^k))`$；特定专家：$`(s^k = g^k(r_e^k))`$                |
| 门控网络           | 聚合专家输出，生成权重向量                                               | $`(w = softmax(MLP(r_g)))`$；聚合表示：$`(z = \sum w_i h_i^k \oplus s^k)`$          |
| 预测塔             | 输出CTR预测值                                                           | $`(\hat{y} = t(z))`$（t(·)为预测函数）                                           |
| 关键设置           | 域特征不直接输入专家，而是与上下文特征结合，适配场景化行为差异             | -                                                                             |

##### 2. 核心模块1：实例软划分协同训练（ISCT）
**目标**：利用主导域数据增强非主导域，缓解特定参数过拟合。  
**四步实现流程**：
1. **数据划分**：将全量数据分为主导域无标签数据$`(x^d)`$与非主导域有标签数据$`(x^o)`$；
2. **分类器训练**：用$`(x^o)`$训练分类器$`(C(·))`$（采用Focal Loss缓解非主导域数据不平衡）；
3. **伪标签生成**：用$`(C(·))`$为$`(x^d)`$生成伪标签$`(\bar{y}_i^d)`$与置信度$`(c_i)`$，形成辅助数据集$`(x^p)`$；
4. **加权损失计算**：
   - 伪标签权重：基于**截断高斯函数**$`(G(·))`$计算，高置信度样本权重高，公式为$`(w_j = G(c_j; \mu, \sigma))`$，其中$`(\mu/\sigma)`$通过EMA动态估计；
   - 总损失：$`(\mathcal{L}_{total} = \sum_{x_i \in X^d,X^o} \mathcal{L}(x_i) + \lambda \sum_{x_j \in X^p} w_j \mathcal{L}(x_j))`$，$`(\lambda=0.7)`$控制伪标签贡献。

##### 3. 核心模块2：软划分域分化网络（SDDN）
**目标**：生成动态参数，削弱主导域对共享参数的压倒性影响。  
**三步实现流程**：
1. **软划分域信息提取**：用ISCT的分类器$`(C(·))`$输出样本的域概率分布$`(p)`$（N-1维，对应非主导域），加权域嵌入$`(e_w = \sum p_k e_d^k)`$（$`(e_d^k)`$为非主导域嵌入）；
2. **分化网络（DN）生成尺度向量**：DN含2个FC层（ReLU+Sigmoid），输入$`(e_d)`$（硬划分域嵌入）与$`(e_w)`$，输出尺度向量$`(\gamma_{ld})`$与$`(\gamma_{lw})`$，$`(\delta=2)`$约束尺度范围；
3. **动态参数调整**：对共享专家的每一层，用尺度向量调整隐藏表示：  
   $`[h_l' = FC_l(h_{l-1}), \quad h_l = \sqrt{\gamma_{ld} \otimes \gamma_{lw}} \otimes h_l']`$  
   其中$`(\otimes)`$为元素积，平方根确保特征尺度一致性。


#### 三、实验验证
##### 1. 实验设置
| 配置项          | 具体内容                                                                 |
|-------------------|--------------------------------------------------------------------------|
| 数据集            | - Ali-CCP（公共）：多域CTR预测数据集，含3个域<br>- 美团外卖（工业）：6个域，D1为主导域（81.16%流量） |
| 基线模型          | 5类方法：<br>- 单域：MLP、Single（单域训练）<br>- 通用：DeepFM、xDeepFM<br>- 多任务：MMoE、PLE<br>- 多域：HMoE、STAR、AdaSparse<br>- 多任务多域：HiNet、PEPNet |
| 超参数            | 嵌入维度=10，隐藏层=[256,128,64]，Adam优化器（lr=1e-3），批大小=4096，dropout=0.2，λ=0.7 |
| 评价指标          | - 离线：AUC、相对提升率（RImp）<br>- 线上：GMV（商品交易总额）、CTR（点击率） |

##### 2. 核心实验结果
#### （1）离线性能：AUC显著优于基线
两大数据集关键域的AUC与相对提升率（RImp）对比（表2节选）：
| 数据集   | 域   | 最佳基线（AUC） | SSCTL（AUC） | RImp  |
|----------|------|-----------------|--------------|-------|
| Ali-CCP  | #3   | PLE（0.6066）   | 0.6095       | +10.23% |
| 美团外卖 | D4   | HiNet（0.6865）  | 0.6907       | +5.31%  |
| 美团外卖 | D6   | PEPNet（0.6777） | 0.6817       | +12.47% |

- 关键结论：SSCTL在非主导域（如美团D6，0.59%流量）提升最显著，验证其缓解过拟合与主导域压倒性的有效性。

#### （2）线上A/B测试：GMV与CTR双提升
在美团外卖5个域部署SSCTL，10天线上测试结果（表3）：
| 域   | PV CTR提升 | GMV提升  |
|------|------------|----------|
| 1    | +0.57%     | +0.54%   |
| 2    | +0.80%     | +1.17%   |
| 3    | +0.22%     | +1.63%   |
| 4    | +1.40%     | +2.06%   |
| 5    | +1.69%     | +2.90%   |

- 关键结论：SSCTL在工业场景下实现业务指标显著提升，证明其实际应用价值。


#### 四、研究结论与价值
1. **技术突破**  
   SSCTL首次将“软划分”与“半监督迁移”结合应用于多域推荐，解决传统架构在数据不平衡场景下的核心痛点，无需依赖用户/物品ID对齐，仅通过特征与域概率分布实现跨域知识迁移。

2. **工业价值**
   - 插件化集成：SDDN可灵活嵌入现有共享-特定架构，无需重构模型；
   - 低计算开销：EMA估计高斯参数、动态参数生成均为轻量级操作，适配大规模流量；
   - 业务增益：线上GMV最高提升2.90%，为平台带来实际收益。

3. **未来方向**
   - 扩展至序列多域推荐场景；
   - 融合因果推断进一步优化域间知识迁移；
   - 适配更多工业场景（如电商、短视频）。


---

### 4. 关键问题
#### 问题1：SSCTL的“软划分”与传统MDR方法的“硬划分”核心差异是什么？这种差异如何解决域边界模糊性问题？
**答案**：  
两者核心差异在于**域划分的动态性与数据关联性**，软划分通过“概率化域归属”解决边界模糊，具体对比如下：  
| 划分方式 | 核心逻辑                                                                 | 域边界处理                          | 数据利用范围                          |
|----------|--------------------------------------------------------------------------|-------------------------------------|---------------------------------------|
| 硬划分（如STAR、HMoE） | 依赖静态域指示器（如“域ID=1”代表首页），样本仅归属单一域                  | 刚性边界，样本非此即彼              | 仅使用本域数据训练特定参数            |
| 软划分（SSCTL）       | 基于分类器输出的域概率分布（如样本归属于D2的概率0.7、D3的概率0.3），样本多域关联 | 柔性边界，样本可归属多个域          | 利用主导域伪标签增强非主导域数据      |

**解决域边界模糊性的机制**：  
传统硬划分无法处理用户跨域随机行为（如用户随机在首页与“夜宵”子域购买同一商品），而软划分通过以下方式适配：
1. 分类器$`(C(·))`$学习样本的域关联特征（如“夜宵时段”特征同时关联首页与夜宵子域），输出多域概率分布；
2. SDDN将硬划分（域指示器）与软划分（概率分布）结合，生成动态参数，使模型同时捕捉“样本的主导域共性”与“非主导域特性”；
3. 实验验证：美团D6域（软划分）AUC比硬划分基线STAR提升4.2%，证明软划分更适配域边界模糊场景。

#### 问题2：SSCTL的ISCT模块为何采用“截断高斯函数”计算伪标签权重？相比传统FixMatch的“固定置信度阈值”，优势是什么？
**答案**：  
ISCT采用截断高斯函数计算权重的核心目的是**平衡伪标签的“数量利用”与“质量控制”**，相比FixMatch的固定阈值，优势在于动态适配置信度分布，具体如下：
1. **截断高斯函数的选择原因**：
   - 高斯分布的**最大熵特性**：确保权重分配对置信度变化敏感，同时避免极端值（如过低置信度样本权重被截断为0，减少噪声）；
   - 动态参数估计：通过EMA实时估计高斯分布的均值$`(\mu)`$与标准差$`(\sigma)`$，无需人工设定阈值，适配不同域的置信度分布差异（如主导域样本置信度普遍高于非主导域）。

2. **相比FixMatch固定阈值的优势**：  
   | 伪标签权重策略 | 核心缺陷                                  | SSCTL截断高斯函数的优势                          |
   |----------------|-------------------------------------------|-------------------------------------------------|
   | FixMatch（固定阈值） | 1. 阈值难调：过高导致样本利用率低，过低引入噪声；2. 静态阈值无法适配不同域置信度分布 | 1. 动态权重：高置信度样本权重高（如0.9置信度权重0.8），低置信度样本权重低（如0.5置信度权重0.1）；2. 噪声抑制：截断低置信度样本（如置信度<μ-2σ权重为0），减少噪声影响 |

   - 实验验证：在美团D5域，ISCT（截断高斯）比FixMatch（阈值0.9）的伪标签利用率提升30%，同时AUC提升1.8%，证明其在样本利用与噪声控制间的平衡优势。

#### 问题3：SSCTL在工业场景中如何平衡“模型复杂度”与“部署效率”？线上GMV提升2.90%的核心原因是什么？
**答案**：
#### （1）模型复杂度与部署效率的平衡机制：
SSCTL通过“轻量级模块设计”与“插件化集成”实现效率平衡，具体措施如下：
1. **模块轻量化**：
   - ISCT：伪标签生成仅需复用分类器$`(C(·))`$，EMA估计高斯参数计算量可忽略（额外计算耗时<5%）；
   - SDDN：分化网络仅含2个FC层，动态参数调整为元素级操作，无额外矩阵运算，单样本推理时间增加<1ms；
2. **插件化集成**：SSCTL可直接嵌入现有共享-特定架构（如美团原STAR模型），无需重构专家层与门控网络，部署周期缩短至1周内；
3. **训练优化**：采用BatchNorm与dropout缓解过拟合，训练 epoch数与基线一致（20-30轮），无额外训练成本。

#### （2）线上GMV提升2.90%的核心原因：
GMV提升源于“推荐精度提升”与“非主导域转化激活”两大因素：
1. **推荐精度提升**：SSCTL缓解非主导域过拟合，特定参数泛化性增强，非主导域CTR提升1.69%（如“下午茶”域推荐更精准，用户点击意愿增强）；
2. **非主导域转化激活**：SDDN削弱主导域压倒性，共享参数融合非主导域知识，主导域向非主导域的流量转化增加（如首页推荐“夜宵”子域商品，带动子域GMV增长）；
3. **数据利用率提升**：ISCT利用主导域伪标签增强非主导域数据，非主导域推荐列表的“长尾商品”覆盖度提升15%，满足用户个性化需求，促进转化。